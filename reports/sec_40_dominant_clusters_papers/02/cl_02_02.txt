---

UT 402
AR Fedorov E., 2024, CEUR WORKSHOP PROC, V3702, P36
TI Multi-Agent Reinforcement Learning Methods with Dynamic Parameters for
   Logistic Tasks
AU Fedorov E.; Nechyporenko O.; Korpan Y.; Neskorodieva T.
TC 0
SO CEUR Workshop Proceedings
PY 2024
AB PART of INDUSTRY 4.0 is BUILDING_COMPUTER_SYSTEMS by combining
   ARTIFICIAL_INTELLIGENCE with ROBOTICS . SUCH_COMPUTER_SYSTEMS play
   AN_IMPORTANT_ROLE in THE_PLANNING of CARGO_TRANSPORTATION in
   SUPPLY_CHAIN_MANAGEMENT . one of THE_APPROACHES to building
   SUCH_COMPUTER_SYSTEMS is THE_USE of MULTI_AGENT_SYSTEMS . the_aim_of
   THE_WORK is to create A_METHODOLOGY for constructing PROACTIVE_AGENTS based
   on REINFORCEMENT_LEARNING to solve THE_PROBLEM of OPTIMAL_PLANNING of
   CARGO_TRANSPORTATION . to solve THE_PROBLEM of INSUFFICIENT_EFFICIENCY of
   COMPUTER_AGENTS , THE_EXISTING_METHODS of STATISTICAL_AND_MACHINE_LEARNING
   were investigated . to DATE , THE_MOST_EFFICIENT_APPROACHES to creating
   PROACTIVE_AGENTS are REINFORCEMENT_LEARNING_APPROACHES . THE_FORMALIZATION
   of THE_FUNCTIONING of PROACTIVE_AGENTS is performed . as A_PART of creating
   A_MODEL for THE_FUNCTIONING of PROACTIVE_AGENTS based on
   REINFORCEMENT_LEARNING , A_PROCEDURE for generating
   A_QUASI_OPTIMAL_ACTION_PLAN is proposed that MODELS_THE_PLANNING_FUNCTION of
   A_PROACTIVE_AGENT , which speeds up THE_DECISION_MAKING_PROCESS .
   MULTI_AGENT_REINFORCEMENT_LEARNING_METHODS are proposed , which are close to
   RANDOM_SEARCH at THE_INITIAL_ITERATIONS , and close to DIRECTED_SEARCH at
   THE_FINAL_ITERATIONS . this is ensured by THE_USE of DYNAMIC_PARAMETERS and
   allows THE_INCREASE in THE_LEARNING_RATE by approximately 10 times while
   maintaining THE_MEAN_SQUARED_ERROR of THE_METHOD . 2024 copyright for this
   paper by its authors . use permitted under creative commons license
   attribution 4.0 international ( cc by 4.0 ) .
DE DYNAMIC_PROGRAMMING; MONTE_CARLO; MULTI_AGENT_SYSTEM; PROACTIVE_AGENT;
   REINFORCEMENT_LEARNING; SUPPLY_CHAIN_MANAGEMENT;
   TEMPORAL_DIFFERENCE_LEARNING
ID DECISION_MAKING; DYNAMIC_PROGRAMMING; LEARNING_ALGORITHMS; LEARNING_SYSTEMS;
   MEAN_SQUARE_ERROR; MONTE_CARLO_METHODS; REINFORCEMENT_LEARNING;
   SUPPLY_CHAIN_MANAGEMENT; AGENT_BASED; CARGO_TRANSPORTATION;
   DYNAMIC_PARAMETERS; MONTE_CARLO; MULTI_AGENT_REINFORCEMENT_LEARNING;
   OPTIMAL_PLANNING; PROACTIVE_AGENT; REINFORCEMENT_LEARNING_METHOD;
   REINFORCEMENT_LEARNINGS; TEMPORAL_DIFFERENCE_LEARNING; MULTI_AGENT_SYSTEMS

---

UT 405
AR Song G., 2024, COMPUT AIDED CHEM ENG, V53, P2905
TI Hierarchical deep reinforcement learning for hydrogen supply chain
   management
AU Song G.; Khaligh V.; Liu J.J.; Na J.
TC 0
SO Computer Aided Chemical Engineering
PY 2024
AB for AN_EFFECTIVE_TRANSITION from FOSSIL_FUEL_BASED_ENERGY_SOURCES to
   RENEWABLE_ENERGY_SOURCES , it is crucial to ACCOMPANY_RESEARCH on the
   DESIGN_AND_OPTIMIZATION of SUPPLY_CHAIN for NEW_ENERGY_SOURCES .
   THE_TRADITIONAL_TOOL for optimizing SUPPLY_CHAIN_MANAGEMENT ( SCM ) , the
   MATHEMATICAL_PROGRAMMING ( MP ) method , has LIMITATIONS in_terms_of
   COMPUTATION_TIME and COST as THE_SCALE and COMPLEXITY of
   THE_SUPPLY_CHAIN_INCREASE . therefore , we need
   A_NEW_POWERFUL_OPTIMIZATION_METHODOLOGY that enables
   REAL_TIME_DECISION_MAKING , considers THE_INTERACTION among
   VARIOUS_COMPONENTS within THE_SUPPLY_CHAIN , and accommodates
   THE_UNCERTAINTIES in DEMAND and ENERGY_SUPPLY . in this study , we proposed
   DEEP_REINFORCEMENT_LEARNING ( DRL ) as A_NEW_TOOL to overcome
   THE_LIMITATIONS of MP and satisfy THE_CONDITIONS required for optimizing SCM
   , as mentioned earlier . furthermore , we aim to compare
   A_SINGLE_AGENT_REINFORCEMENT_LEARNING ( SARL ) system with a
   MULTI_AGENT_REINFORCEMENT_LEARNING ( MARL ) system . OUR_MODEL achieves
   SUCCESSFUL_PERFORMANCE by converging to A_VALUE like THE_OPTIMUM of THE_MP .
   2024 elsevier b . v .
DE HIERARCHICAL_DEEP_REINFORCEMENT_LEARNING; HYDROGEN_SUPPLY_CHAIN;
   MULTI_AGENT; OPERATION_SCHEDULING; OPTIMIZATION

---

UT 420
AR Wang H./1, 2024, LECT NOTES COMPUT SCI, V14965 LNCS, P470
TI Robust Multi-vehicle Routing with Communication Enhanced Multi-agent
   Reinforcement Learning for Last-Mile Logistics
AU Wang H./1; Wang S.; Wang S./1; Zhou X.
TC 0
SO Lecture Notes in Computer Science (including subseries Lecture Notes in
   Artificial Intelligence and Lecture Notes in Bioinformatics)
PY 2024
AB THE_VEHICLE_ROUTING_PROBLEM ( VRP ) is crucial for optimizing LOGISTICS in
   APPLICATIONS such_as EXPRESS_SYSTEMS , INDUSTRIAL_WAREHOUSING , and
   ON_DEMAND_DELIVERY . LAST_MILE_LOGISTICS_PRESENT_UNIQUE_CHALLENGES due_to
   DYNAMIC_AND_UNCERTAIN_PICKUP_DEMANDS , requiring
   REAL_TIME_ROUTING_ADJUSTMENTS and EFFICIENT_MANAGEMENT of DELIVERY_SCHEDULES
   . EXISTING_HEURISTIC_BASED_METHODS rely heavily on MANUAL_RULES and are
   inadequate for HIGHLY_DYNAMIC_ENVIRONMENTS , while RL_BASED_METHODS lack
   MODELS for COOPERATIVE_PROBLEMS . to address THESE_ISSUES , we propose the
   COMMUNICATION_ENHANCED_MULTI_AGENT_REINFORCEMENT_LEARNING ( CEMRL )
   framework . CEMRL_UTILIZES_CONTEXT encoding to unify ENVIRONMENT_FEATURES
   and LOCAL_OBSERVATIONS and employs
   A_TRANSFORMER_BASED_COMMUNICATION_ENHANCEMENT_MODULE for
   EFFICIENT_MULTI_AGENT_COMMUNICATION . OUR_EXTENSIVE_EXPERIMENTS on
   A_REAL_WORLD_DATASET demonstrate THAT_CEMRL significantly outperforms
   STATE_OF_THE_ART baselines in TRAVEL_DISTANCE and OVERDUE_RATES , validating
   ITS_EFFECTIVENESS in COMPLEX_LOGISTICS_SCENARIOS . the author ( s ) , under
   exclusive license to springer nature singapore pte ltd . 2024 .
DE LAST_MILE_LOGISTICS; MULTI_AGENT_REINFORCEMENT_LEARNING; VEHICAL_ROUTING
ID VEHICLE_ROUTING; LAST_MILE; LAST_MILE_LOGISTIC;
   MULTI_AGENT_REINFORCEMENT_LEARNING; MULTI_VEHICLES; ON_DEMANDS;
   PICK_UP_DEMANDS; REAL_TIME_ROUTING; ROUTINGS; VEHICAL_ROUTING;
   VEHICLE_ROUTING_PROBLEMS; REINFORCEMENT_LEARNING

---

UT 423
AR Nishi T./1, 2024, J ADV MECH DES SYST MANUF, V18
TI Distributed optimization algorithm for multi-agent optimization problems
   using consensus control
AU Nishi T./1; Debuchi N.; Liu Z.
TC 0
SO Journal of Advanced Mechanical Design, Systems and Manufacturing
PY 2024
AB THE_DISTRIBUTED_OPTIMIZATION_ALGORITHMS using CONSENSUS_CONTROL are proposed
   for solving MULTI_AGENT_OPTIMIZATION_PROBLEMS .
   THE_MULTI_AGENT_OPTIMIZATION_PROBLEM has
   DISCRETE_AND_CONTINUOUS_DECISION_VARIABLES to minimize THE_SUM of
   LOCAL_COST_FUNCTIONS with LOCAL_AND_GLOBAL_CONSTRAINTS . THE_PROBLEM is
   formulated as A_MIXED_INTEGER_PROGRAMMING_PROBLEM . in this study , we
   propose TWO_DISTRIBUTED_OPTIMIZATION_ALGORITHMS to solve THE_PROBLEM .
   A_FEASIBLE_SOLUTION is obtained by solving
   THE_CONTINUOUS_OPTIMIZATION_PROBLEM using
   AN_EXISTING_DISTRIBUTED_OPTIMIZATION_METHOD with CONSENSUS_CONTROL and
   solving THE_DISCRETE_OPTIMIZATION_PROBLEM by fixing 0 1 variables . in the
   proposed method 1 , ALL_POSSIBLE_COMBINATIONS of A_BINARY_VARIABLES are
   searched . since ALL_COMBINATIONS are searched , THE_EXACT_OPTIMAL_SOLUTION
   can be obtained . however , it is difficult to apply to LARGE_SCALE_PROBLEMS
   . in the proposed method 2 , we derive THE_SOLUTION of BINARY_VARIABLES by
   using LAGRANGIAN_DECOMPOSITION_AND_COORDINATION_APPROACH . the proposed
   method 2 can provide APPROXIMATE_SOLUTIONS for MORE_COMPLEX_PROBLEMS within
   A_PRACTICAL_COMPUTATION_TIME . THESE_METHODS are successfully implemented to
   obtain NEAR_OPTIMAL_SOLUTIONS in A_DISTRIBUTED_ENVIRONMENT for
   SUPPLY_CHAIN_PLANNING_PROBLEMS for MULTIPLE_COMPANIES and
   MULTI_AGENT_UNIT_COMMITMENT_PROBLEM . THE_NUMBER of INFORMATION_EXCHANGES in
   THE_TWO_PROPOSED_METHODS is evaluated . THE_INFORMATION_EXCHANGE for
   THESE_METHODS can significantly reduce THE_DATA_EXCHANGE compared with
   THE_CONVENTIONAL_CENTRALIZED_OPTIMIZATION_METHOD . COMPUTATIONAL_EXPERIMENTS
   for THE_MULTI_AGENT_UNIT_COMMITMENT_PROBLEMS and
   SUPPLY_CHAIN_PLANNING_PROBLEMS for MULTIPLE_COMPANIES demonstrate
   THE_EFFECTIVENESS of THE_PROPOSED_METHODS . 2024 the japan society of
   mechanical engineers .
DE DISTRIBUTED_OPTIMIZATION;
   LAGRANGIAN_DECOMPOSITION_AND_COORDINATION_APPROACH; SUBGRADIENT_METHOD;
   SUPPLY_CHAIN_PLANNING; UNIT_COMMITMENT
ID INFORMATION_DISSEMINATION; INTEGER_LINEAR_PROGRAMMING; INTEGER_PROGRAMMING;
   LAGRANGE_MULTIPLIERS; MIXED_INTEGER_LINEAR_PROGRAMMING;
   MULTIOBJECTIVE_OPTIMIZATION; OPTIMIZATION_ALGORITHMS; CONSENSUS_CONTROL;
   DISTRIBUTED_OPTIMIZATION; LAGRANGIAN_DECOMPOSITION;
   LAGRANGIAN_DECOMPOSITION_AND_COORDINATION_APPROACH; MULTI_AGENT;
   OPTIMIZATION_ALGORITHMS; OPTIMIZATION_PROBLEMS; SUB_GRADIENT_METHODS;
   SUPPLY_CHAIN_PLANNING; UNIT_COMMITMENT; COST_FUNCTIONS

---

UT 429
AR Shu X., 2024, SENSORS, V24
TI Energy-Saving Multi-Agent Deep Reinforcement Learning Algorithm for Drone
   Routing Problem
AU Shu X.; Lin A.; Wen X.
TC 0
SO Sensors
PY 2024
AB with THE_RAPID_ADVANCEMENT of DRONE_TECHNOLOGY , THE_EFFICIENT_DISTRIBUTION
   of DRONES has garnered SIGNIFICANT_ATTENTION . central to THIS_DISCOURSE is
   THE_ENERGY_CONSUMPTION of DRONES , a CRITICAL_METRIC for assessing
   ENERGY_EFFICIENT_DISTRIBUTION_STRATEGIES . accordingly , this study delves
   into THE_ENERGY_CONSUMPTION_FACTORS affecting DRONE_DISTRIBUTION .
   A_PRIMARY_CHALLENGE in DRONE_DISTRIBUTION lies in devising optimal ,
   ENERGY_EFFICIENT_ROUTES for DRONES . however ,
   TRADITIONAL_ROUTING_ALGORITHMS , predominantly HEURISTIC based , exhibit
   CERTAIN_LIMITATIONS . THESE_ALGORITHMS often rely on HEURISTIC_RULES and
   EXPERT_KNOWLEDGE , which can constrain THEIR_ABILITY to escape LOCAL_OPTIMA
   . motivated by THESE_SHORTCOMINGS , we propose a novel
   MULTI_AGENT_DEEP_REINFORCEMENT_LEARNING_ALGORITHM that integrates
   A_DRONE_ENERGY_CONSUMPTION_MODEL , namely emadrl . THE_EMADRL_ALGORITHM
   first formulates THE_DRONE_ROUTING_PROBLEM within
   A_MULTI_AGENT_REINFORCEMENT_LEARNING_FRAMEWORK . it subsequently designs
   A_STRATEGY_NETWORK_MODEL comprising MULTIPLE_AGENT_NETWORKS , tailored to
   address THE_NODE_ADJACENCY and masking COMPLEXITIES typical of
   MULTI_DEPOT_VEHICLE_ROUTING_PROBLEM .
   TRAINING_UTILIZES_STRATEGY_GRADIENT_ALGORITHMS and ATTENTION_MECHANISMS .
   furthermore , LOCAL_AND_SAMPLING_SEARCH_STRATEGIES are introduced to
   ENHANCE_SOLUTION_QUALITY . EXTENSIVE_EXPERIMENTATION_DEMONSTRATES that
   emadrl consistently achieves HIGH_QUALITY_SOLUTIONS swiftly .
   A_COMPARATIVE_ANALYSIS against CONTEMPORARY_ALGORITHMS reveals
   EMADRL_SUPERIOR_ENERGY_EFFICIENCY , with AVERAGE_ENERGY_SAVINGS of 5.96 %
   and MAXIMUM_SAVINGS reaching 12.45 % . thus , THIS_APPROACH offers
   A_PROMISING_NEW_AVENUE for OPTIMIZING_ENERGY_CONSUMPTION in
   LAST_MILE_DISTRIBUTION_SCENARIOS . 2024 by the authors .
DE DEEP_REINFORCEMENT_LEARNING; DRONE_ROUTING; ENERGY_SAVINGS; MULTIPLE_AGENTS
ID ADVERSARIAL_MACHINE_LEARNING; DRONES; ENERGY_SAVING; HEURISTIC_ALGORITHMS;
   LEARNING_ALGORITHMS; MULTI_AGENT_SYSTEMS; REINFORCEMENT_LEARNING;
   ROUTING_ALGORITHMS; VEHICLE_ROUTING; DRONE_ROUTING; ENERGY_SAVINGS;
   ENERGY_CONSUMPTION; ENERGY_SAVINGS; MULTI_AGENT; MULTIPLE_AGENTS;
   REINFORCEMENT_LEARNING_ALGORITHMS; REINFORCEMENT_LEARNINGS;
   ROUTING_PROBLEMS; ROUTINGS; ALGORITHM; ARTICLE; CONTROLLED_STUDY;
   DEEP_REINFORCEMENT_LEARNING; DRONE; ENERGY; ENERGY_CONSERVATION;
   ENERGY_CONSUMPTION; REINFORCEMENT_LEARNING (MACHINE_LEARNING);
   DEEP_REINFORCEMENT_LEARNING

---

UT 431
AR Mehra A., 2024, IEEE TRANS INTELL TRANSP SYST, V25, P20574
TI Last Mile: A Novel, Hotspot-Based Distributed Path-Sharing Network for Food
   Deliveries
AU Mehra A.; Singh D.; Raychoudhury V.; Mathur A.; Saha S.
TC 0
SO IEEE Transactions on Intelligent Transportation Systems
PY 2024
AB DELIVERY of ITEMS from THE_PRODUCER to THE_CONSUMER has experienced
   SIGNIFICANT_GROWTH over THE_PAST_DECADE and has been greatly fueled by
   THE_RECENT_PANDEMIC . AMAZON_FRESH , GRUBHUB , UBEREATS , POSTMATES ,
   instacart , and DOORDASH are rapidly growing and are
   SHARING_THE_SAME_BUSINESS_MODEL of CONSUMER_ITEMS or FOOD_DELIVERY .
   EXISTING_FOOD_DELIVERY_METHODS are SUB_OPTIMAL because EACH_DELIVERY is
   individually optimized to go directly from THE_PRODUCER to THE_CONSUMER via
   THE_SHORTEST_TIME_PATH . we observe A_SIGNIFICANT_SCOPE for reducing
   THE_COSTS associated with completing DELIVERIES under THE_CURRENT_MODEL .
   for this , we MODEL_OUR_FOOD_DELIVERY_PROBLEM as
   A_MULTI_OBJECTIVE_OPTIMIZATION , where CONSUMER_SATISFACTION and
   DELIVERY_COSTS , both , need to be optimized . taking INSPIRATION from
   THE_SUCCESS of RIDE_SHARING in THE_TAXI_INDUSTRY , we propose
   DELIVERAI_A_REINFORCEMENT_LEARNING_BASED_PATH SHARING_ALGORITHM . unlike
   PREVIOUS_ATTEMPTS for PATH_SHARING , DELIVERAI can provide REAL_TIME , time
   EFFICIENT_DECISION_MAKING using A_REINFORCEMENT_LEARNING enabled
   AGENT_SYSTEM . OUR_NOVEL_AGENT_INTERACTION_SCHEME_LEVERAGES_PATH_SHARING
   among DELIVERIES to reduce the TOTAL_DISTANCE_TRAVELED while keeping
   THE_DELIVERY_COMPLETION_TIME under CHECK . we generate and test
   OUR_METHODOLOGY vigorously on A_SIMULATION_SETUP using REAL_DATA from
   THE_CITY of CHICAGO . OUR_RESULTS show that DELIVERAI can reduce
   THE_DELIVERY_FLEET_SIZE by 15 % , THE_DISTANCE traveled by 16 % , and 50 %
   higher FLEET_UTILIZATION_W . r.t POINT_TO_POINT_DELIVERY_SYSTEMS . 2000 2011
   ieee .
DE DISTRIBUTED_SYSTEMS; LAST_MILE_DELIVERY; MULTI_AGENT_INTERACTION;
   MULTI_HOP_ROUTING; REINFORCEMENT_LEARNING; RIDE_SHARING
ID FLEET_OPERATIONS; DISTRIBUTED_SYSTEMS; FOOD_DELIVERY; HOTSPOTS; LAST_MILE;
   LAST_MILE_DELIVERY; MULTI_AGENT_INTERACTION; MULTI_HOP_ROUTING;
   REINFORCEMENT_LEARNINGS; RIDE_SHARING; SHARING_NETWORK;
   REINFORCEMENT_LEARNING

---

UT 438
AR Zhang B., 2024, SUSTAINABILITY, V16
TI Leveraging Multi-Agent Reinforcement Learning for Digital Transformation in
   Supply Chain Inventory Optimization
AU Zhang B.; Tan W.J.; Cai W.; Zhang A.N.
TC 0
SO Sustainability (Switzerland)
PY 2024
AB in today S_VOLATILE_SUPPLY_CHAIN ( SC ) environment , COMPETITION has
   shifted beyond INDIVIDUAL_COMPANIES to THE_ENTIRE_SC_ECOSYSTEM . reducing
   OVERALL_SC_COSTS is crucial for SUCCESS and BENEFITS_ALL_PARTICIPANTS .
   ONE_EFFECTIVE_APPROACH to achieve this is through DIGITAL_TRANSFORMATION ,
   enhancing SC_COORDINATION via INFORMATION_SHARING , and establishing
   DECISION_POLICIES among ENTITIES . however , THE_RISK of
   UNAUTHORIZED_LEAKAGE of SENSITIVE_INFORMATION_POSES_A_SIGNIFICANT_CHALLENGE
   . we aim to propose a PRIVACY_PRESERVING_MULTI_AGENT_REINFORCEMENT_LEARNING
   ( PMARL ) method to ENHANCE_SC_VISIBILITY , COORDINATION , and PERFORMANCE
   during INVENTORY_MANAGEMENT while effectively mitigating THE_RISK of
   INFORMATION_LEAKAGE by leveraging MACHINE_LEARNING_TECHNIQUES .
   THE_SC_INVENTORY_POLICIES are optimized using
   MULTI_AGENT_REINFORCEMENT_LEARNING with
   ADDITIONAL_SC_CONNECTIVITY_INFORMATION to improve TRAINING_PERFORMANCE .
   THE_SIMULATION_BASED_EVALUATION_RESULTS illustrate that THE_PMARL_METHOD
   surpasses TRADITIONAL_OPTIMIZATION_METHODS in achieving COST_PERFORMANCE
   comparable to FULL_VISIBILITY_METHODS , all while preserving PRIVACY . this
   research addresses THE_DUAL_OBJECTIVES of
   INFORMATION_SECURITY_AND_COST_REDUCTION in SC_INVENTORY_MANAGEMENT ,
   aligning with THE_BROADER_TREND of DIGITAL_TRANSFORMATION . 2024 by the
   authors .
DE DATA_DRIVEN_DECISION_MAKING; DIGITAL_TRANSFORMATION;
   MULTI_AGENT_REINFORCEMENT_LEARNING; PRIVACY_PRESERVING;
   SUPPLY_CHAIN_INVENTORY_MANAGEMENT
ID DECISION_MAKING; MACHINE_LEARNING; OPTIMIZATION; PERFORMANCE_ASSESSMENT;
   SIMULATION; SUPPLY_CHAIN_MANAGEMENT

---

UT 440
AR Khankhour H., 2024, LECT NOTES INF SYS ORGAN, V71 LNISO, P114
TI An Artificial Intelligence Approach to Enhance the Optimization of the
   Vehicle Routing Problem
AU Khankhour H.; Abouchabaka J.; Rafalia N.
TC 0
SO Lecture Notes in Information Systems and Organisation
PY 2024
AB SUSTAINABLE_DEVELOPMENT_INVOLVES_AN_ECONOMIC_PLAN that
   PRIORITIZES_MEETING_BASIC_HUMAN_NEEDS while also taking CARE of
   OUR_ENVIRONMENT through the USE_OF_TECHNOLOGY . A_KEY_STEP we can take
   towards THIS_GOAL is optimizing OUR_SUPPLY_CHAIN_PROCESSES to reduce
   AIR_POLLUTION_AND_TRAFFIC_CONGESTION on OUR_PLANET . THIS_APPROACH benefits
   ALL_CITIZENS by reducing DAILY_TRAFFIC_JAMS . to achieve this , we are
   focused on solving THE_VEHICLE_ROUTING_PROBLEM ( VRP ) with TIME_WINDOWS and
   SYNCHRONIZATION_CONSTRAINTS . our MULTI_AGENT_SYSTEM_UTILIZES_GENETIC and
   METAHEURISTIC_ALGORITHMS , such_as SIMULATED_ANNEALING and
   THE_NEAREST_NEIGHBOUR_METHOD , to generate EFFICIENT_ROUTES for
   THREE_VEHICLES in response to CUSTOMER_REQUESTS . OUR_OBJECTIVE is to
   calculate THE_TOTAL_DISTANCE for EACH_ROUTE and assess THE_PROBABILITY of
   stopping for EACH_VEHICLE . through PARALLEL_PROCESSING , OUR_AGENTS collect
   and ANALYZE_DATA related to VRP_PROBLEMS for CUSTOMER_LOCATIONS and
   CLASSIFY_VEHICLE_DATA based on THEIR_MODEL and TYPE . by utilizing
   THESE_METHODS , we can achieve SUSTAINABLE_DEVELOPMENT while also improving
   THE_LIVES of CITIZENS . the author ( s ) , under exclusive license to
   springer nature switzerland ag 2024 .
DE ARTIFICIAL_INTELLIGENCE; GENETIC_ALGORITHMS; MACHINE_LEARNING;
   MULTI_AGENT_SYSTEM; PARALLEL_PROCESSING; TRAFFIC_CONGESTION; VRP

---

UT 442
AR Li Z./2, 2024, PROC INT CONF ELECTRON BUS (ICEB), V24, P308
TI Optimizing Inventory Management using a Multi-Agent LLM System
AU Li Z./2; Ksibi A.; Xu X.
TC 0
SO Proceedings of the International Conference on Electronic Business (ICEB)
PY 2024
AB EFFECTIVE_INVENTORY_MANAGEMENT requires A_COMPREHENSIVE_CAPABILITY to
   FORECAST_DEMAND and OPTIMIZE_STOCK_LEVELS , traditionally reserved for
   HUMAN_EXPERTISE . EMERGING_AI_METHODS , while providing EFFECTIVE_SOLUTIONS
   through DEEP_LEARNING_MODELS and DATA_ANALYTICS , often lack THE_FLEXIBILITY
   to incorporate DYNAMIC_MARKET_INSIGHTS and REAL_TIME_DATA . by leveraging
   THE_DIVERSE_CAPABILITIES of multiple dynamically interacting
   LARGE_LANGUAGE_MODELS ( LLMS ) , we can overcome THESE_LIMITATIONS and
   develop A_NEW_CLASS of AI_DRIVEN_INVENTORY_MANAGEMENT_SYSTEMS . this paper
   presents A_MULTI_AGENT_FRAMEWORK comprising A_PROJECT_MANAGER_AGENT ,
   A_SALES_FORECASTING_AGENT , and AN_INVENTORY_MANAGER_AGENT , which
   autonomously collaborate to address INVENTORY_MANAGEMENT_CHALLENGES .
   THE_AGENTS dynamically adjust INVENTORY_PLANS and maintain
   PRODUCT_AVAILABILITY through SELF and MUTUAL_CORRECTIONS .
   SIMULATION_RESULTS demonstrate A_SIGNIFICANT_INCREASE in
   THE_INVENTORY_TURNOVER_RATIO , REDUCED_SHIPPING_COSTS and holding FEES , and
   A_SUBSTANTIAL_DECREASE in TOTAL_COST , all while maintaining
   A_ZERO_STOCKOUT_RATE . OUR_FRAMEWORK showcases THE_POTENTIAL of synergizing
   THE_INTELLIGENCE of LLMS , THE_PRECISION of STATISTICAL_MODELING , and
   THE_DYNAMIC_COLLABORATIONS among DIVERSE_AGENTS , opening NOVEL_AVENUES for
   automating and optimizing SUPPLY_CHAIN_MANAGEMENT . 2024 international
   consortium for electronic business . all rights reserved .
DE INVENTORY_MANAGEMENT; LARGE_LANGUAGE_MODELS (LLMS); MULTI_AGENT_SYSTEMS;
   SUPPLY_CHAIN_OPTIMIZATION
ID COST_REDUCTION; ELECTRONIC_TRADING; FINANCIAL_MARKETS;
   INFORMATION_MANAGEMENT; INVENTORY_CONTROL; PROBLEM_ORIENTED_LANGUAGES;
   PROJECT_MANAGEMENT; SUPPLY_CHAIN_MANAGEMENT; SUPPLY_CHAINS;
   EFFECTIVE_SOLUTION; HUMAN_EXPERTISE; INVENTORY_MANAGEMENT; LANGUAGE_MODEL;
   LARGE_LANGUAGE_MODEL; MODELLING_SYSTEMS; MULTI_AGENT; MULTIAGENT_SYSTEMS
   (MASS); STOCK_LEVEL; SUPPLY_CHAIN_OPTIMIZATION; DEEP_LEARNING

---

UT 443
AR Liu X., 2024, PROD OPER MANAGE
TI Multi-Agent Deep Reinforcement Learning for Multi-Echelon Inventory
   Management
AU Liu X.; Hu M.; Peng Y.; Yang Y./3
TC 0
SO Production and Operations Management
PY 2024
AB we apply HETEROGENEOUS_AGENT_PROXIMAL_POLICY_OPTIMIZATION ( HAPPO ) ,
   A_MULTI_AGENT_DEEP_REINFORCEMENT_LEARNING_ALGORITHM , to
   THE_DECENTRALIZED_MULTI_ECHELON_INVENTORY_MANAGEMENT_PROBLEMS in
   BOTH_A_SERIAL_SUPPLY_CHAIN and A_SUPPLY_CHAIN_NETWORK . we also examine
   whether THE_UPFRONT_ONLY_INFORMATION_SHARING_MECHANISM used in MADRL helps
   alleviate THE_BULLWHIP_EFFECT . OUR_RESULTS show that POLICIES constructed
   by HAPPO achieve LOWER_OVERALL_COSTS than POLICIES constructed by
   SINGLE_AGENT_DEEP_REINFORCEMENT_LEARNING and OTHER_HEURISTIC_POLICIES . also
   , the application of HAPPO_RESULTS in A_LESS_SIGNIFICANT_BULLWHIP_EFFECT
   than POLICIES constructed by SINGLE_AGENT_DEEP_REINFORCEMENT_LEARNING where
   INFORMATION is not shared among ACTORS . somewhat surprisingly , compared to
   using THE_OVERALL_COSTS of THE_SYSTEM as A_MINIMIZATION_TARGET for
   EACH_ACTOR , HAPPO achieves LOWER_OVERALL_COSTS when THE_MINIMIZATION_TARGET
   for EACH_ACTOR is A_COMBINATION of ITS_OWN_COSTS and THE_OVERALL_COSTS of
   THE_SYSTEM . OUR_RESULTS provide A_NEW_PERSPECTIVE on THE_BENEFIT of
   INFORMATION_SHARING inside THE_SUPPLY_CHAIN that helps alleviate
   THE_BULLWHIP_EFFECT and improve THE_OVERALL_PERFORMANCE of THE_SYSTEM .
   UPFRONT_INFORMATION_SHARING and ACTION_COORDINATION in MODEL_TRAINING among
   ACTORS is essential , with the former even more essential , for improving
   A_SUPPLY_CHAIN_OVERALL_PERFORMANCE when applying MADRL . NEITHER_ACTORS
   being fully self interested nor ACTORS being FULLY_SYSTEM focused leads_to
   THE_BEST_PRACTICAL_PERFORMANCE of POLICIES learned and constructed by MADRL
   . OUR_RESULTS also verify MADRL_POTENTIAL in solving
   VARIOUS_MULTI_ECHELON_INVENTORY_MANAGEMENT_PROBLEMS with
   COMPLEX_SUPPLY_CHAIN_STRUCTURES and in NON_STATIONARY_MARKET_ENVIRONMENTS .
   the author ( s ) 2024 .
DE BULLWHIP_EFFECT; MULTI_AGENT_REINFORCEMENT_LEARNING;
   MULTI_ECHELON_INVENTORY_MANAGEMENT


---
