---

UT 329
AR Zhang K., 2023, PHYS A STAT MECH APPL, V611
TI Graph attention reinforcement learning with flexible matching policies for
   multi-depot vehicle routing problems
AU Zhang K.; Lin X.; Li M./2
TC 15
SO Physica A: Statistical Mechanics and its Applications
PY 2023
AB MULTI_DEPOT_VEHICLE_ROUTING_PROBLEM with SOFT_TIME_WINDOWS ( MD_VRPSTW ) is
   A_VALUABLE_PRACTICAL_ISSUE in URBAN_LOGISTICS . however , HEURISTIC_METHODS
   may fail to GENERATE_HIGH_QUALITY_SOLUTIONS for MASSIVE_PROBLEMS instantly .
   thus , this paper presents a NOVEL_REINFORCEMENT_LEARNING_ALGORITHM
   integrated with GRAPH_ATTENTION_NETWORK ( GAT_RL ) to efficiently solve
   THE_PROBLEM . THIS_METHOD utilizes THE_ENCODERDECODER_ARCHITECTURE to
   produce ROUTES for VEHICLES starting from DIFFERENT_DEPOTS iteratively .
   THE_ENCODER_ARCHITECTURE employs GRAPH_ATTENTION_NETWORK to mine
   THE_COMPLEX_SPATIALTEMPORAL_CORRELATIONS within TIME_WINDOWS . then , the
   DECODER_ARCHITECTURE_DESIGNS_FIXED_ORDER and FULL_PAIR_MATCHING_POLICIES to
   GENERATE_SOLUTIONS . after OFF_LINE_TRAINING , EXPERIMENTS show that
   THIS_APPROACH consistently OUTPERFORMS_GOOGLE or TOOLS with
   NEGLIGIBLE_COMPUTATIONAL_TIME . particularly , THE_ROBUSTNESS of
   THE_PRE_TRAINED_MODEL is validated under MULTIPLE_SOURCES of VARIATIONS and
   UNCERTAINTIES , including CUSTOMER_DEPOT_NUMBERS , VEHICLE_CAPACITIES , and
   EN_ROUTE_TRAFFIC_CONDITIONS . 2023 elsevier b . v .
DE GRAPH_ATTENTION; MULTI_AGENT; MULTI_DEPOT; REINFORCEMENT_LEARNING;
   SOFT_TIME_WINDOW
ID DECODING; HEURISTIC_METHODS; ITERATIVE_METHODS; LEARNING_ALGORITHMS;
   LEARNING_SYSTEMS; MULTI_AGENT_SYSTEMS; NETWORK_ARCHITECTURE;
   VEHICLE_ROUTING; VEHICLES; FLEXIBLE_MATCHING; GRAPH_ATTENTION;
   HIGH_QUALITY_SOLUTIONS; MULTI_AGENT; MULTI_DEPOTS;
   MULTI_DEPOT_VEHICLE_ROUTING_PROBLEMS; PRACTICAL_ISSUES;
   REINFORCEMENT_LEARNINGS; SOFT_TIME_WINDOWS; URBAN_LOGISTICS;
   REINFORCEMENT_LEARNING

---

UT 350
AR Arishi A., 2023, J MANAG ANAL, V10, P493
TI A multi-agent deep reinforcement learning approach for solving the multi-
   depot vehicle routing problem
AU Arishi A.; Krishnan K.
TC 13
SO Journal of Management Analytics
PY 2023
AB THE_MULTI_DEPOT_VEHICLE_ROUTING_PROBLEM ( MDVRP ) is one of
   THE_MOST_ESSENTIAL_AND_USEFUL_VARIANTS of
   THE_TRADITIONAL_VEHICLE_ROUTING_PROBLEM ( VRP ) in SUPPLY_CHAIN_MANAGEMENT (
   SCM ) and LOGISTICS_STUDIES . MANY_SUPPLY_CHAINS ( SC ) choose
   THE_JOINT_DISTRIBUTION of MULTIPLE_DEPOTS to cut TRANSPORTATION_COSTS and
   DELIVERY_TIMES . however , THE_ABILITY to deliver QUALITY_AND_FAST_SOLUTIONS
   for MDVRP remains A_CHALLENGING_TASK . TRADITIONAL_OPTIMIZATION_APPROACHES
   in OPERATION_RESEARCH ( or ) may not be practical to solve MDVRP in
   REAL_TIME . with THE_LATEST_DEVELOPMENTS in ARTIFICIAL_INTELLIGENCE ( AI ) ,
   it becomes feasible to apply DEEP_REINFORCEMENT_LEARNING ( DRL ) for solving
   COMBINATORIAL_ROUTING_PROBLEMS . this paper proposes a new
   MULTI_AGENT_DEEP_REINFORCEMENT_LEARNING_MODEL to solve MDVRP .
   EXTENSIVE_EXPERIMENTS are conducted to evaluate THE_PERFORMANCE of
   THE_PROPOSED_APPROACH . RESULTS show that THE_DEVELOPED_MADRL_MODEL can
   rapidly capture RELATIVE_INFORMATION embedded in GRAPHS and effectively
   produce QUALITY_SOLUTIONS in REAL_TIME . 2023 antai college of economics and
   management , shanghai jiao tong university .
DE ARTIFICIAL_INTELLIGENCE; COMBINATORIAL_OPTIMIZATION;
   MULTI_AGENT_DEEP_REINFORCEMENT_LEARNING;
   MULTI_DEPOT_VEHICLE_ROUTING_PROBLEM; SUPPLY_CHAIN_MANAGEMENT
ID COMBINATORIAL_OPTIMIZATION; DEEP_LEARNING; LEARNING_SYSTEMS;
   MULTI_AGENT_SYSTEMS; REINFORCEMENT_LEARNING; VEHICLE_ROUTING; VEHICLES;
   JOINT_DISTRIBUTIONS; MULTI_AGENT; MULTI_AGENT_DEEP_REINFORCEMENT_LEARNING;
   MULTI_DEPOT_VEHICLE_ROUTING_PROBLEMS; REAL_TIME;
   REINFORCEMENT_LEARNING_APPROACH; REINFORCEMENT_LEARNING_MODELS;
   REINFORCEMENT_LEARNINGS; SUPPLY_CHAIN_LOGISTICS; SUPPLY_CHAIN_MANAGEMENT

---

UT 351
AR Piao M., 2023, APPL SCI, V13
TI A Supply Chain Inventory Management Method for Civil Aircraft Manufacturing
   Based on Multi-Agent Reinforcement Learning
AU Piao M.; Zhang D.; Lu H.; Li R./1
TC 5
SO Applied Sciences (Switzerland)
PY 2023
AB EFFECTIVE_SUPPLY_CHAIN_INVENTORY_MANAGEMENT is crucial for
   LARGE_SCALE_MANUFACTURING_INDUSTRIES such_as CIVIL_AIRCRAFT and
   AUTOMOBILE_MANUFACTURING to ensure EFFICIENT_MANUFACTURING . generally ,
   THE_MAIN_MANUFACTURER makes THE_ANNUAL_INVENTORY_MANAGEMENT_PLAN , and
   CONTACTS with SUPPLIERS when SOME_MATERIAL is approaching
   CRITICAL_INVENTORY_LEVEL according to THE_ACTUAL_PRODUCTION_SCHEDULE , which
   increases THE_DIFFICULTY of INVENTORY_MANAGEMENT . in RECENT_YEARS ,
   MANY_RESEARCHERS have focused on using REINFORCEMENT_LEARNING_METHOD to
   study INVENTORY_MANAGEMENT_PROBLEMS . CURRENT_APPROACHES were mainly
   designed for THE_SUPPLY_CHAIN with SINGLE_NODE_MULTI_MATERIAL or
   MULTI_NODE_SINGLE_MATERIAL_MODE , which are not suitable to
   THE_CIVIL_AIRCRAFT_MANUFACTURING_SUPPLY_CHAIN with
   MULTI_NODE_MULTI_MATERIAL_MODE . to deal with THIS_PROBLEM , we formulated
   THE_PROBLEM as a PARTIALLY_OBSERVABLE_MARKOV_DECISION_PROCESS_MODEL and
   proposed A_MULTI_AGENT_REINFORCEMENT_LEARNING_METHOD for
   SUPPLY_CHAIN_INVENTORY_MANAGEMENT , in which
   THE_DUAL_POLICY_AND_INFORMATION_TRANSMISSION_MECHANISM was designed to help
   THE_SUPPLY_CHAIN_PARTICIPANT improve
   THE_GLOBAL_INFORMATION_UTILIZATION_EFFICIENCY of THE_SUPPLY_CHAIN and
   THE_COORDINATION_EFFICIENCY with OTHER_PARTICIPANTS . THE_EXPERIMENT_RESULTS
   show that OUR_METHOD has about 45 % PERFORMANCE improvement on EFFICIENCY
   compared with CURRENT_REINFORCEMENT_LEARNING_BASED_METHODS . 2023 by the
   authors .
DE INVENTORY_MANAGEMENT; MULTI_AGENT_REINFORCEMENT_LEARNING; SUPPLY_CHAIN

---

UT 327
AR Shi L., 2023, ELECTRONICS (SWITZERLAND), V12
TI Stochastic Fixed-Time Tracking Control for the Chaotic Multi-Agent-Based
   Supply Chain Networks with Nonlinear Communication
AU Shi L.; Guo W.; Wang L.; Bekiros S.; Alsubaie H.; Alotaibi A.; Jahanshahi H.
TC 4
SO Electronics (Switzerland)
PY 2023
AB THE_MULTI_AGENT_BASED_SUPPLY_CHAIN_NETWORK is A_DYNAMIC_SYSTEM consisting of
   MULTIPLE_SUBCHAINS connected by INFORMATION_FLOWS , MATERIAL_FLOWS and
   CAPITAL_FLOW , etc . THE_CONSENSUS of MULTI_AGENT_SYSTEMS is often applied
   to THE_COOPERATION between SUBCHAINS and INVENTORY_MANAGEMENT in
   SUPPLY_CHAIN_NETWORKS . considering THE_UBIQUITOUS_EXTERNAL_DISTURBANCES ,
   THIS_PAPER mainly considers THE_FIXED_TIME_CONSENSUS of
   A_STOCHASTIC_THREE_ECHELON_MULTI_AGENT_BASED_SUPPLY_CHAIN_SYSTEM .
   A_NONLINEAR_FEEDBACK_FIXED_TIME_CONTROL_PROTOCOL is constructed for ensuring
   THE_CONSENSUS of THE_CONSIDERED_SUPPLY_CHAIN_NETWORK . using
   THE_STABILITY_THEORY of STOCHASTIC_DIFFERENTIAL_EQUATIONS ,
   SUFFICIENT_CONDITIONS for THE_FIXED_TIME_CONSENSUS and
   THE_UPPER_BOUND_ESTIMATION of THE_SETTLING_TIME are obtained . finally ,
   THE_VALIDITY of THE_CONTROL_PROTOCOL and THE_CORRECTNESS of
   THE_THEORETICAL_ANALYSIS are revealed by NUMERICAL_SIMULATION . 2022 by the
   authors .
DE FIXED_TIME_TRACKING_CONTROL; MULTI_AGENT_SYSTEMS; NONLINEAR_COMMUNICATION;
   STOCHASTIC_DISTURBANCE; SUPPLY_CHAIN_NETWORKS

---

UT 340
AR Tajima E., 2023, J JPN IND MANAGE ASSOC, V73, P234
TI Effectiveness of a Multi-Agent Cooperation Game in a Multi-Stage Supply
   Chain – Beer Game Experiment –
AU Tajima E.; Ishigaki A.; Takashima R.; Nishida H.; Okammoto T.
TC 4
SO Journal of Japan Industrial Management Association
PY 2023
AB in SUPPLY_CHAIN_MANAGEMENT , THE_BULLWHIP_EFFECT leads_to AN_INCREASE in
   COSTS and OPPORTUNITY_LOSS_RISK , and imposes A_SIGNIFICANT_BURDEN on
   COMPANY_MANAGEMENT . therefore , controlling THE_BULLWHIP_EFFECT in
   THE_SUPPLY_CHAIN is AN_IMPORTANT_ISSUE . THE_COMMON_STRATEGY and
   INFORMATION_SHARING among COMPANIES are effective in reducing
   THE_BULLWHIP_EFFECT . THESE_EFFECTS have been shown in MANY_STUDIES .
   however , in RECENT_YEARS , in THE_INCREASINGLY_COMPLEX_SUPPLY_CHAIN , it is
   very difficult for EACH_COMPANY to have AN_ACCURATE_AND_TIMELY_UNDERSTANDING
   of THE_INFORMATION that affects THEIR_ACTIONS . this makes it difficult to
   share INFORMATION and COMMON_STRATEGIES throughout THE_SUPPLY_CHAIN . this
   study considers A_MODEL of COOPERATION between SOME_COMPANIES in
   THE_SUPPLY_CHAIN to share INFORMATION and COMMON_STRATEGIES . STUDIES that
   aim to reduce THE_BULLWHIP_EFFECT and THE_TOTAL_COST in THE_SUPPLY_CHAINS
   involve DEMAND_FORECASTING , INVENTORY_POLICY and SAFETY_STOCK_OPTIMIZATION
   . THE_PROPOSED_MODEL focuses on improving COMPANY_STRATEGIES by combining
   MULTIPLE_STRATEGIES and ANALYZES_WHICH_POLICIES and ACTIONS improve
   THE_PERFORMANCE of THE_ENTIRE_SUPPLY_CHAIN . in this study ,
   A_MULTI_STAGE_SUPPLY_CHAIN_MODEL is constructed using MULTI_AGENT_SIMULATION
   to identify THE_OPTIMAL_STRATEGY by analyzing THE_EFFECT of COOPERATION
   between COMPANIES in_terms_of THE_BULLWHIP_EFFECT and THE_TOTAL_COST . this
   study identifies A_TENDENCY for AN_THE_OPTIMAL_STRATEGY to be used by
   EACH_COMPANY . in_addition , THE_RESULTS will be validated by
   A_BEER_GAME_DEMONSTRATION to examine EFFECTIVE_STRATEGIES in
   A_REAL_SUPPLY_CHAIN . 2023 japan industrial management association . all
   rights reserved .
DE BEER_GAME; BULLWHIP_EFFECT; MULTI_AGENT_SIMULATION; SUPPLY_CHAIN
ID INFORMATION_DISSEMINATION; OPTIMAL_SYSTEMS; SUPPLY_CHAIN_MANAGEMENT;
   BEER_GAME; BULLWHIP_EFFECTS; COMMON_STRATEGY; COMPANY_MANAGEMENT;
   INFORMATION_SHARING; INFORMATION_STRATEGY; MULTI_AGENT_COOPERATION;
   MULTI_AGENTS_SIMULATIONS; MULTI_STAGES; OPTIMAL_STRATEGIES;
   MULTI_AGENT_SYSTEMS

---

UT 318
AR Jo H., 2023, LECT NOTES ELECTR ENG, V913, P963
TI Multi-agent Reinforcement Learning-Based UAS Control for Logistics
   Environments
AU Jo H.; Lee H.; Jeon S.; Kaliappan V.K.; Anh Nguyen T.; Min D.; Lee J.-W.
TC 2
SO Lecture Notes in Electrical Engineering
PY 2023
AB with RECENT_TECHNOLOGICAL_DEVELOPMENTS , THE_UAS ( UNMANNED_AERIAL_SYSTEM )
   has been recognized for ITS_VALUE and USEFULNESS in VARIOUS_FIELDS .
   PRIOR_RESEARCHERS have utilized SEVERAL_DRONES in COLLABORATION to navigate
   to achieve COMMON_GOALS such_as TARGET_TRACKING , RESCUE_OPERATIONS , and
   TARGET_FINDING with MULTI_UAS_SYSTEMS .
   MULTI_AGENT_REINFORCEMENT_LEARNING_ALGORITHMS are A_TYPE of
   ARTIFICIAL_INTELLIGENCE_TECHNOLOGY in which MANY_AGENTS collaborate to
   perform TASKS . when A_MULTI_UAS_COOPERATIVE_NAVIGATION_TECHNIQUE is
   deployed to A_COMPLICATED_ENVIRONMENT such_as AN_URBAN_LOGISTICS_SYSTEM ,
   the AGENTS ' LEARNING_CAPACITIES become more tedious . in this study , we
   present what is termed THE_IMPROVED_MULTI_ACTOR_ATTENTION_CRITIC_APPROACH ,
   A_MODIFIED_MULTI_AGENT_REINFORCEMENT_LEARNING_METHOD for APPLICATION to
   URBAN_AIR_MOBILITY_LOGISTIC_SERVICES . A_VIRTUAL_SIMULATION_ENVIRONMENT
   based on UNITY is created to validate THE_SUGGESTED_METHOD . in
   THE_VIRTUAL_ENVIRONMENT , THE_REAL_WORLD_SITUATION of
   UAS_LOGISTICS_DEVELOPMENT_SERVICES is replicated . when THE_FINDINGS are
   compared to those of OTHER_LANDMARK_REINFORCEMENT_ALGORITHMS ,
   IMAAC_SHOWS_A_HIGHER_LEARNING_RATE than those by THE_OTHER_ALGORITHMS when
   utilized in MULTI_AGENT_SYSTEMS . 2023 , the author ( s ) , under exclusive
   license to springer nature singapore pte ltd .
DE ACTOR_ATTENTION_CRITIC; AIR_LOGISTICS; MULTI_AGENT_REINFORCEMENT_LEARNING;
   URBAN_AERIAL_MOBILITY
ID AIR_MOBILITY; INTELLIGENT_AGENTS; LEARNING_ALGORITHMS; LEARNING_SYSTEMS;
   MULTI_AGENT_SYSTEMS; NAVIGATION; REINFORCEMENT_LEARNING; TARGET_TRACKING;
   UNMANNED_AERIAL_VEHICLES (UAV); VIRTUAL_REALITY; ACTOR_ATTENTION_CRITIC;
   AIR_LOGISTIC; MULTI_ACTORS; MULTI_AGENT_REINFORCEMENT_LEARNING;
   RESCUE_OPERATIONS; SYSTEM_CONTROL; TARGETS_TRACKING;
   TECHNOLOGICAL_DEVELOPMENT; UNMANNED_AERIAL_SYSTEMS; URBAN_AERIAL_MOBILITY;
   ANTENNAS

---

UT 334
AR Okada T., 2023, INTL J ADV  COMPUT SCI APPL, V14, P65
TI Supply Chain Network Model using Multi-Agent Reinforcement Learning for
   COVID-19
AU Okada T.; Sato H.; Kubo M.
TC 2
SO International Journal of Advanced Computer Science and Applications
PY 2023
AB the covid 19 VACCINATION_MANAGEMENT in JAPAN has revealed MANY_PROBLEMS .
   THE_NUMBER of VACCINES available was clearly less than THE_NUMBER of PEOPLE
   who wanted to be vaccinated . initially , THE_SYSTEM was managed by making
   RESERVATIONS with AGE_GROUP utilizing VACCINATION_COUPONS . after
   THE_SECOND_ROUND of VACCINATIONS , ONLY_APPOINTMENTS for VACCINATION_DATES
   were coordinated and VACCINATION_SITES were set up in SHIBUYA_WARD where
   THE_VACCINE could be taken freely . under A_SHORTAGE of VACCINE_SUPPLY ,
   THE_INABILITY to make APPOINTMENTS arose from A_FAILURE to properly
   ESTIMATE_DEMAND . in_addition , THE_VACCINE expired due_to
   INADEQUATE_INVENTORY_MANAGEMENT , resulting_in THE_VACCINE being discarded .
   this is considered to be A_SUPPLY_CHAIN_PROBLEM in which APPROPRIATE_SUPPLY
   could not be provided in response to DEMAND . in response to THIS_PROBLEM ,
   this paper examines whether it is possible to avoid SHORTAGE and
   STOCK_DISCARDS by A_DECENTRALIZED_MANAGEMENT_SYSTEM for easy on
   SITE_INVENTORY_CONTROL instead_of A_CENTRALIZED_MANAGEMENT_SYSTEM in
   REAL_WORLD . based on A_MULTI_AGENT_MODEL , A_MODEL was created to
   REDISTRIBUTE_INVENTORY to CLIENTS by predicting FUTURE_SHORTAGE based on
   DEMAND_FLUCTUATIONS and PAST_INVENTORY_LEVELS . THE_MODEL was constructed by
   adopting THE_KANTO_REGION . THE_VALIDATION_RESULTS of THE_MODEL showed that
   THE_NUMBER of DISCARDS was reduced by about 70 % and OUT_OF_STOCKS by about
   12 % as_a_result of LEARNING_THE_DISPERSION_MANAGEMENT and
   OUT_OF_STOCK_FORECASTING 2023 , international journal of advanced computer
   science and applications . all rights reserved .
DE AGENT_BASED_MODEL; COVID_19_VACCINATION; MULTI_AGENT_REINFORCEMENT_LEARNING;
   SUPPLY_CHAIN_MANAGEMENT
ID AUTONOMOUS_AGENTS; COMPUTATIONAL_METHODS; INVENTORY_CONTROL;
   LEARNING_SYSTEMS; MULTI_AGENT_SYSTEMS; REINFORCEMENT_LEARNING;
   SUPPLY_CHAIN_MANAGEMENT; VACCINES; AGE_GROUPS; AGENT_BASED_MODEL;
   COVID_19_VACCINATION; INVENTORY_MANAGEMENT;
   MULTI_AGENT_REINFORCEMENT_LEARNING; NETWORK_MODELS; NUMBER_OF_PEOPLES;
   OUT_OF_STOCK; SUPPLY_CHAIN_NETWORK; VACCINE_SUPPLIES; COVID_19

---

UT 390
AR Zhu Y., 2023, ADV NEURAL INF PROCES SYST, V36
TI OFCOURSE: A Multi-Agent Reinforcement Learning Environment for Order
   Fulfillment
AU Zhu Y.; Zhan Y.; Huang X.; Chen Y./4; Chen Y./1; Wei J.; Feng W.; Zhou Y.;
   Hu H.; Ye J.
TC 2
SO Advances in Neural Information Processing Systems
PY 2023
AB THE_DRAMATIC_GROWTH of GLOBAL_E_COMMERCE has led to A_SURGE in DEMAND for
   efficient and cost EFFECTIVE_ORDER_FULFILLMENT which can increase customers
   ' SERVICE_LEVELS and sellers ' competitiveness . however ,
   MANAGING_ORDER_FULFILLMENT is challenging due_to A_SERIES of
   INTERDEPENDENT_ONLINE_SEQUENTIAL_DECISION_MAKING_PROBLEMS . to clear
   THIS_HURDLE , rather_than solving THE_PROBLEMS separately as attempted in
   SOME_RECENT_RESEARCHES , this paper proposes A_METHOD based on
   MULTI_AGENT_REINFORCEMENT_LEARNING to integratively solve THE_SERIES of
   INTERCONNECTED_PROBLEMS , encompassing ORDER_HANDLING , PACKING and PICKUP ,
   STORAGE , order consolidation , and LAST_MILE_DELIVERY . in_particular , we
   MODEL_THE_INTEGRATED_PROBLEM as A_MARKOV_GAME , wherein A_TEAM of
   AGENTS_LEARNS_A_JOINT_POLICY via interacting with A_SIMULATED_ENVIRONMENT .
   since NO_SIMULATED_ENVIRONMENT supporting
   THE_COMPLETE_ORDER_FULFILLMENT_PROBLEM exists , we devise
   ORDER_FULFILLMENT_COOPERATIVE_MULTI_AGENT_REINFORCEMENT_LEARNING
   SCALABLE_ENVIRONMENT ( OFCOURSE ) in THE_OPENAI_GYM_STYLE , which allows
   REPRODUCTION and RE_UTILIZATION to build CUSTOMIZED_APPLICATIONS . by
   constructing THE_FULFILLMENT_SYSTEM in OFCOURSE , we optimize A_JOINT_POLICY
   that solves THE_INTEGRATED_PROBLEM , facilitating
   SEQUENTIAL_ORDER_WISE_OPERATIONS across ALL_FULFILLMENT_UNITS and minimizing
   THE_TOTAL_COST of fulfilling ALL_ORDERS within THE_PROMISED_TIME . with
   OFCOURSE , we also demonstrate that THE_JOINT_POLICY learned by
   MULTI_AGENT_REINFORCEMENT_LEARNING_OUTPERFORMS_THE_COMBINATION of
   LOCALLY_OPTIMAL_POLICIES . THE_SOURCE_CODE of OFCOURSE is available at :
   https : / GITHUB . COM_GITYIHENG_OFCOURSE . 2023 neural information
   processing systems foundation . all rights reserved .
ID CELL_PROLIFERATION; COMPUTER_AIDED_INSTRUCTION; COST_EFFECTIVENESS;
   MULTI_AGENT_SYSTEMS; REINFORCEMENT_LEARNING; COST_EFFECTIVE;
   CUSTOMER_SERVICE_LEVELS; DECISION_MAKING_PROBLEM; EFFECTIVE_ORDER;
   GLOBAL_E_COMMERCES; LEARNING_ENVIRONMENTS;
   MULTI_AGENT_REINFORCEMENT_LEARNING; ORDER_FULFILLMENT;
   SEQUENTIAL_DECISION_MAKING; SIMULATED_ENVIRONMENT; DECISION_MAKING

---

UT 342
AR Rajbala, 2023, CONTEMP STUD RISKS IN EMERG TECHNOL PART A, P111
TI Intelligent agent-based supply chain management using service-oriented
   architecture
AU Rajbala; Singh Nain P.K.; Kumar A.
TC 1
SO Contemporary Studies of Risks in Emerging Technology, Part A
PY 2023
AB purpose : TECHNOLOGICAL_INNOVATIONS and FRAMEWORKS that provide A_FRAMEWORK
   for UNIFICATION have evolved to improve INFORMATION_EXCHANGE across
   ORGANISATIONAL_UNITS and INFORMATION_SECURITY .
   THESE_INTEGRATION_TECHNOLOGIES share and COMMUNICATE_INFORMATION using
   DEFINED_PROTOCOLS and DIFFERENT_DATA . SERVICE_ORIENTED_ARCHITECTURE ( SOA )
   is A_SIGNIFICANT_EMERGING_APPROACH that enables
   MODULAR_DESIGN_SOLUTION_CONSTRUCTION . methodology : THESE_DESIGNS are
   beneficial when MANY_APPS operating on DIFFERENT_ARCHITECTURES and
   NETWORKS_NEED to connect . A_WELL_DEFINED_STRATEGY and
   COMPANY_SPECIFIC_GUIDELINES are essential for ensuring
   THE_FIRM_SYSTEMATIC_ADOPTION of SUCH_AN_ARCHITECTURE .
   THE_CRITICAL_COMPONENTS of MASSOASCM ' ( MULTI_AGENT_SYSTEM_SERVICE oriented
   ARCHITECTURE_SUPPLY_CHAIN_MANAGEMENT ' are A_MULTI_AGENT_SYSTEM ( MAS ) ,
   A_SERVICEORIENTED_STRUCTURE , and SUPPLIER_MANAGEMENT . THE_MASSOASCM_MODEL
   has been made , and A_PRODUCTION_UNIT has been made to show how it works .
   findings : it has been stated that it saves DEVELOPMENT_COSTS , and
   INVENTORY_MANAGEMENT , all of which are CRITICAL_CONCERNS in ANY_COMPANY .
   OUR_GOAL is to create AN_INVENTORY_CONTROL_APPROACH that relies on MAS and
   SOA but also A_SIMULATION that demonstrates how it works and may enhance
   SUPPLY_CHAIN_MANAGEMENT_PRODUCTIVITY in A_PRODUCTION_PLANT . practical
   implications : THE_SCM_IMPLEMENTATION comprises THREE_DIFFERENT_SERVICES :
   SCM , SOA , and MAS . THESE_FACILITIES are constructed , maintained ,
   planned , and implemented individually before being brought together
   collectively using MAS_AND_SOA_TECHNIQUES . 2023 by rajbala , pawan kumar
   singh nain and avadhesh kumar .
DE EXTENSION_MARKUP_LANGUAGE; INTELLIGENT_AGENTS; MAS_FRAMEWORKS;
   MULTIAGENT_SYSTEMS; SUPPLY_CHAIN_MANAGEMENT;
   SUPPLY_CHAIN_PROCEDURES_TERM_REFERRING

---

UT 365
AR Khirwar M., 2023, LECT NOTES COMPUT SCI, V14174 LNAI, P619
TI Cooperative Multi-agent Reinforcement Learning for Inventory Management
AU Khirwar M.; Gurumoorthy K.S.; Jain A.A.; Manchenahally S.
TC 1
SO Lecture Notes in Computer Science (including subseries Lecture Notes in
   Artificial Intelligence and Lecture Notes in Bioinformatics)
PY 2023
AB with REINFORCEMENT_LEARNING ( RL ) for INVENTORY_MANAGEMENT ( i am ) being
   A_NASCENT_FIELD of RESEARCH , APPROACHES tend to be limited to simple ,
   LINEAR_ENVIRONMENTS with IMPLEMENTATIONS that are MINOR_MODIFICATIONS of off
   the SHELF_RL_ALGORITHMS . scaling THESE_SIMPLISTIC_ENVIRONMENTS to
   A_REAL_WORLD_SUPPLY_CHAIN comes with A_FEW_CHALLENGES , such_as minimizing
   THE_COMPUTATIONAL_REQUIREMENTS of THE_ENVIRONMENT , specifying
   AGENT_CONFIGURATIONS that are representative of DYNAMICS at
   REAL_WORLD_STORES and WAREHOUSES , and specifying A_REWARD_FRAMEWORK that
   encourages DESIRABLE_BEHAVIOR across THE_WHOLE_SUPPLY_CHAIN . in this work ,
   we present A_SYSTEM with A_CUSTOM_GPU_PARALLELIZED_ENVIRONMENT that consists
   of ONE_WAREHOUSE and MULTIPLE_STORES , A_NOVEL_ARCHITECTURE for
   AGENT_ENVIRONMENT_DYNAMICS incorporating ENHANCED_STATE_AND_ACTION_SPACES ,
   and A_SHARED_REWARD_SPECIFICATION that seeks to optimize for
   A_LARGE_RETAILER_SUPPLY_CHAIN_NEEDS . EACH_VERTEX in THE_SUPPLY_CHAIN_GRAPH
   is AN_INDEPENDENT_AGENT that , based on ITS_OWN_INVENTORY , able to place
   REPLENISHMENT_ORDERS to the VERTEX_UPSTREAM . THE_WAREHOUSE_AGENT ,
   aside_from placing ORDERS from THE_SUPPLIER , has THE_SPECIAL_PROPERTY of
   also being able to CONSTRAIN_REPLENISHMENT to STORES downstream , which
   results in it LEARNING_AN_ADDITIONAL_ALLOCATION_SUB_POLICY . we achieve
   A_SYSTEM that outperforms STANDARD_INVENTORY_CONTROL_POLICIES such_as
   A_BASE_STOCK_POLICY and OTHER_RL_BASED_SPECIFICATIONS for ONE_PRODUCT , and
   lay out A_FUTURE_DIRECTION of WORK for MULTIPLE_PRODUCTS . 2023 , the author
   ( s ) , under exclusive license to springer nature switzerland ag .
DE ALLOCATION_POLICY; INVENTORY_MANAGEMENT; MULTI_AGENT_REINFORCEMENT_LEARNING;
   SHARED_REWARD
ID INVENTORY_CONTROL; LEARNING_SYSTEMS; MULTI_AGENT_SYSTEMS;
   REINFORCEMENT_LEARNING; SPECIFICATIONS; SUPPLY_CHAINS; ALLOCATION_POLICIES;
   INVENTORY_MANAGEMENT; MULTI_AGENT_REINFORCEMENT_LEARNING; NASCENT_FIELD;
   REAL_WORLD; REINFORCEMENT_LEARNING_ALGORITHMS; REINFORCEMENT_LEARNINGS;
   RESEARCH_APPROACH; SHARED_REWARD; SIMPLEST_LINEAR; WAREHOUSES


---
